{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import clear_output\n",
    "from numpy import arange\n",
    "import os \n",
    "from sklearn.metrics import r2_score\n",
    "import ta\n",
    "from ta import *\n",
    "import talib\n",
    "#from rfpimp import permutation_importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import ta\n",
    "import warnings\n",
    "import time \n",
    "from IPython.display import clear_output\n",
    "from pyti.exponential_moving_average import exponential_moving_average as EMA\n",
    "import xlrd \n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "import sys\n",
    "import decimal\n",
    "import pyodbc \n",
    "import pandas.io.sql\n",
    "import smtplib\n",
    "import mimetypes\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email import encoders\n",
    "from email.message import Message\n",
    "from email.mime.audio import MIMEAudio\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.image import MIMEImage\n",
    "from email.mime.text import MIMEText\n",
    "from ta import *\n",
    "import talib\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "#import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "from elasticsearch import Elasticsearch\n",
    "import socket \n",
    "import sys  \n",
    "import csv\n",
    "import socket\n",
    "from datetime import datetime\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from collections import namedtuple\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import style\n",
    "from functools import reduce \n",
    "import re\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section  1.   Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>date</th>\n",
       "      <th>askopen</th>\n",
       "      <th>askhigh</th>\n",
       "      <th>asklow</th>\n",
       "      <th>askclose</th>\n",
       "      <th>_volume</th>\n",
       "      <th>_volume_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUD/CHF</td>\n",
       "      <td>H1</td>\n",
       "      <td>2010-01-03 22:00:00</td>\n",
       "      <td>0.929795</td>\n",
       "      <td>0.93230</td>\n",
       "      <td>0.929795</td>\n",
       "      <td>0.93090</td>\n",
       "      <td>249.0</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUD/CHF</td>\n",
       "      <td>H1</td>\n",
       "      <td>2010-01-03 23:00:00</td>\n",
       "      <td>0.930900</td>\n",
       "      <td>0.93130</td>\n",
       "      <td>0.929300</td>\n",
       "      <td>0.92969</td>\n",
       "      <td>554.0</td>\n",
       "      <td>554.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUD/CHF</td>\n",
       "      <td>H1</td>\n",
       "      <td>2010-01-04 00:00:00</td>\n",
       "      <td>0.929690</td>\n",
       "      <td>0.93140</td>\n",
       "      <td>0.928450</td>\n",
       "      <td>0.93020</td>\n",
       "      <td>1663.0</td>\n",
       "      <td>1663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUD/CHF</td>\n",
       "      <td>H1</td>\n",
       "      <td>2010-01-04 01:00:00</td>\n",
       "      <td>0.930200</td>\n",
       "      <td>0.93085</td>\n",
       "      <td>0.929050</td>\n",
       "      <td>0.93030</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>1188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUD/CHF</td>\n",
       "      <td>H1</td>\n",
       "      <td>2010-01-04 02:00:00</td>\n",
       "      <td>0.930300</td>\n",
       "      <td>0.93075</td>\n",
       "      <td>0.928905</td>\n",
       "      <td>0.92955</td>\n",
       "      <td>749.0</td>\n",
       "      <td>749.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Currency TimeFrame                 date   askopen  askhigh    asklow  \\\n",
       "0  AUD/CHF        H1  2010-01-03 22:00:00  0.929795  0.93230  0.929795   \n",
       "1  AUD/CHF        H1  2010-01-03 23:00:00  0.930900  0.93130  0.929300   \n",
       "2  AUD/CHF        H1  2010-01-04 00:00:00  0.929690  0.93140  0.928450   \n",
       "3  AUD/CHF        H1  2010-01-04 01:00:00  0.930200  0.93085  0.929050   \n",
       "4  AUD/CHF        H1  2010-01-04 02:00:00  0.930300  0.93075  0.928905   \n",
       "\n",
       "   askclose  _volume  _volume_new  \n",
       "0   0.93090    249.0        249.0  \n",
       "1   0.92969    554.0        554.0  \n",
       "2   0.93020   1663.0       1663.0  \n",
       "3   0.93030   1188.0       1188.0  \n",
       "4   0.92955    749.0        749.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ####### importing the raw data for H4 AND D1 tinme frame \n",
    "\n",
    "#path = \"C:/Users/Avinash Mishra/Avinash/Python Codes/WSG Market/17 June 2020 Updated Raw Data\"\n",
    "\n",
    "# path = \"C:/Users/WELCOME/WSG Markets/Making Model Features 20201809/\"\n",
    "\n",
    "\n",
    "# df_h1= pd.read_csv(path + \"H1 Raw Data - 10 years.csv\")\n",
    "# df_h4= pd.read_csv(path + \"H4 Raw Data - 10 years.csv\")\n",
    "# df_d1= pd.read_csv(path + \"D1 Raw Data - 10 years.csv\")\n",
    "\n",
    "\n",
    "#path_sep_oct_data = \"C:/Users/Administrator/WSG Markets/10 Year data creation for model/Creating model data for all strategy combined/Model data for TP optimization/3 month data/Raw data/\"\n",
    "#df_h1= pd.read_csv(path_sep_oct_data + \"H1 FXCM 4 month data for TP optimization.csv\")\n",
    "#df_h4= pd.read_csv(path_sep_oct_data + \"H4 FXCM 4 month data for TP optimization.csv\")\n",
    "#df_d1= pd.read_csv(path_sep_oct_data + \"D1 FXCM 4 month data for TP optimization.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_sep_oct_data = \"C:/Users/Administrator/WSG Markets/10 Year data creation for model/Creating model data for all strategy combined/Strategy - 1_1 TP Ratio/Raw Data/\"\n",
    "\n",
    "\n",
    "\n",
    "df_h1= pd.read_csv(path_sep_oct_data + \"H1 FXCM data.csv\")\n",
    "df_h4= pd.read_csv(path_sep_oct_data + \"H4 FXCM data.csv\")\n",
    "df_d1= pd.read_csv(path_sep_oct_data + \"D1 FXCM data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_h1 = df_h1.rename(columns = {'H1_avg_open':'askopen','H1_avg_high':'askhigh',\n",
    "                              'H1_avg_low':'asklow','H1_avg_close':'askclose',\n",
    "                              'H1_volume':'_volume','H1_volume_new':'_volume_new',\n",
    "                             'H1_Timeframe':'TimeFrame'})\n",
    "\n",
    "#df_h4 = df_h4.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "df_h4 = df_h4.rename(columns = {'H4_avg_open':'askopen','H4_avg_high':'askhigh',\n",
    "                              'H4_avg_low':'asklow','H4_avg_close':'askclose',\n",
    "                              'H4_volume':'_volume','H4_volume_new':'_volume_new',\n",
    "                             'H4_Timeframe':'TimeFrame'})\n",
    "\n",
    "df_d1 = df_d1.rename(columns = {'D1_avg_open':'askopen','D1_avg_high':'askhigh',\n",
    "                              'D1_avg_low':'asklow','D1_avg_close':'askclose',\n",
    "                              'D1_volume':'_volume','D1_volume_new':'_volume_new',\n",
    "                              'D1_Timeframe':'TimeFrame'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = df_h1.append(df_h4)\n",
    "df = df.append(df_d1)\n",
    "# df = df.rename(columns = {'Timeframe':'TimeFrame','tickqty':'_volume'})\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "# #path = \"C:/Users/Avinash Mishra/Avinash/Python Codes/WSG Market/17 June 2020 Updated Raw Data\"\n",
    "\n",
    "# path = \"C:/Users/WELCOME/WSG Markets/Making Model Features 20201809/\"\n",
    "\n",
    "\n",
    "# # df_h1= pd.read_csv(path + \"D1 data 2020 latest.csv\")\n",
    "# df_h4= pd.read_csv(path + \"H4 Raw Data - 10 years.csv\")\n",
    "# df = df_h4.head(500)\n",
    "# # df_d1= pd.read_csv(path + \"D1 Raw Data - 10 years.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# # df = df_h1.append(df_h4)\n",
    "# # df = df.append(df_d1)\n",
    "# df = df.rename(columns = {'Timeframe':'TimeFrame','tickqty':'_volume'})\n",
    "# df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Currency'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AUD/CHF', 'AUD/JPY', 'AUD/NZD', 'AUD/USD', 'CAD/CHF', 'CAD/JPY',\n",
       "       'CHF/JPY', 'EUR/AUD', 'EUR/CAD', 'EUR/CHF', 'EUR/GBP', 'EUR/JPY',\n",
       "       'EUR/NZD', 'EUR/USD', 'GBP/AUD', 'GBP/CAD', 'GBP/CHF', 'GBP/JPY',\n",
       "       'GBP/NZD', 'GBP/USD', 'NZD/CAD', 'NZD/CHF', 'NZD/JPY', 'NZD/USD',\n",
       "       'USD/CAD', 'USD/CHF', 'USD/JPY'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Currency'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Currency</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AUD/CHF</th>\n",
       "      <th>D1</th>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H1</th>\n",
       "      <td>70831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H4</th>\n",
       "      <td>18428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AUD/JPY</th>\n",
       "      <th>D1</th>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H1</th>\n",
       "      <td>70884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">USD/CHF</th>\n",
       "      <th>H1</th>\n",
       "      <td>70808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H4</th>\n",
       "      <td>18418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">USD/JPY</th>\n",
       "      <th>H1</th>\n",
       "      <td>70856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H4</th>\n",
       "      <td>18438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date\n",
       "Currency TimeFrame       \n",
       "AUD/CHF  D1          3500\n",
       "         H1         70831\n",
       "         H4         18428\n",
       "AUD/JPY  D1          3500\n",
       "         H1         70884\n",
       "...                   ...\n",
       "USD/CHF  H1         70808\n",
       "         H4         18418\n",
       "USD/JPY  H1         70856\n",
       "         D1          3500\n",
       "         H4         18438\n",
       "\n",
       "[81 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### getting the count of rows for each timeframe by currency \n",
    "row_count = pd.DataFrame()\n",
    "row_count = pd.DataFrame(df.groupby(by=['Currency','TimeFrame'])['date'].count())\n",
    "row_count.sort_values(by=['Currency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Code for creation of variables for the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####\n",
    "\n",
    "\n",
    "def model_data_prep(Currency,Timeframe):\n",
    "    \n",
    "    global final_data\n",
    "    global counter\n",
    "    counter+=1\n",
    "    \n",
    "    print(\"Currency-----> \"  + str(Currency))\n",
    "    print(\"Timeframe-----> \"  + str(Timeframe))\n",
    "    print(\"Counter-----> \"  + str(counter))\n",
    "    \n",
    "\n",
    "\n",
    "    df_prep =df[(df['TimeFrame'] == Timeframe) & (df['Currency'] == Currency)]\n",
    "    df_prep = df_prep.reset_index(drop = True)\n",
    "\n",
    "\n",
    "    #-------------Making of Stochastic And EMA Data---------------------------#\n",
    "\n",
    "\n",
    "    df_prep['_stock_%K'] = ta.momentum.stoch(df_prep['askhigh'],df_prep['asklow'],\\\n",
    "                                                         df_prep['askclose'], n=20, fillna=False)\n",
    "\n",
    "    df_prep['_stoch_%D'] = ta.momentum.stoch_signal(df_prep['askhigh'],df_prep['asklow'],\\\n",
    "                                                                df_prep['askclose'], n=20, d_n=6, fillna=False)\n",
    "\n",
    "    df_prep['_stoch_slow_%K'] = df_prep['_stoch_%D']\n",
    "\n",
    "    df_prep['_stoch_slow_%D'] = df_prep['_stoch_slow_%K'].rolling(window=6).mean()\n",
    "\n",
    "    df_prep['_stoch_direction'] = np.where((df_prep['_stoch_slow_%K'])>(df_prep['_stoch_slow_%D']),1,0).astype('float32')\n",
    "    df_prep['_stoch_slow_0_1'] = df_prep['_stoch_direction']\n",
    "\n",
    "\n",
    "\n",
    "    df_prep['_Ema_20'] = ta.trend.ema_indicator(df_prep['askclose'], n=20, fillna=False)\n",
    "\n",
    "    df_prep['_Ema_200'] = ta.trend.ema_indicator(df_prep['askclose'], n=200, fillna=False)\n",
    "\n",
    "    df_prep['Ema_direction'] = np.where((df_prep['_Ema_20'])>(df_prep['_Ema_200']),1,0).astype('float32')\n",
    "\n",
    "    #df_prep['Ema_0_1'] = df_prep['_Ema_direction']\n",
    "\n",
    "    df_prep = add_all_ta_features(df_prep, \"askopen\",\"askhigh\",\"asklow\",\\\n",
    "                                     \"askclose\",\"_volume\", fillna=False)\n",
    "\n",
    "\n",
    "    #-------------Making of CandleStick Data ------------------------------------#\n",
    "\n",
    "    op = df_prep['askopen']\n",
    "    hi = df_prep['askhigh']\n",
    "    lo = df_prep['asklow']\n",
    "    cl = df_prep['askclose']\n",
    "\n",
    "    #------------DOJI---------------#\n",
    "\n",
    "    df_prep['CDLDOJI']            = talib.CDLDOJI(op, hi, lo, cl)\n",
    "    df_prep['CDLDOJISTAR']        = talib.CDLDOJISTAR(op, hi, lo, cl)\n",
    "    df_prep['CDLMORNINGDOJISTAR'] = talib.CDLMORNINGDOJISTAR(op, hi, lo, cl)\n",
    "    df_prep['CDLEVENINGDOJISTAR'] = talib.CDLEVENINGDOJISTAR(op, hi, lo, cl)\n",
    "    df_prep['CDLDRAGONFLYDOJI']   = talib.CDLDRAGONFLYDOJI(op, hi, lo, cl)\n",
    "    df_prep['CDLGRAVESTONEDOJI']  = talib.CDLGRAVESTONEDOJI(op, hi, lo, cl)\n",
    "\n",
    "        #------------STAR---------------#\n",
    "\n",
    "    df_prep['CDLMORNINGSTAR']  = talib.CDLMORNINGSTAR(op, hi, lo, cl)\n",
    "    df_prep['CDLSHOOTINGSTAR'] = talib.CDLSHOOTINGSTAR(op, hi, lo, cl)\n",
    "    df_prep['CDLEVENINGSTAR']  = talib.CDLEVENINGSTAR(op, hi, lo, cl)\n",
    "\n",
    "\n",
    "        #------------HAMMER--------------#\n",
    "\n",
    "    df_prep['CDLHAMMER']         = talib.CDLHAMMER(op, hi, lo, cl)\n",
    "    df_prep['CDLHANGINGMAN']     = talib.CDLHANGINGMAN(op, hi, lo, cl)\n",
    "    df_prep['CDLINVERTEDHAMMER'] = talib.CDLINVERTEDHAMMER(op, hi, lo, cl)\n",
    "\n",
    "\n",
    "        #------------HARAMI---------------#\n",
    "\n",
    "    df_prep['CDLHARAMI']      = talib.CDLHARAMI(op, hi, lo, cl)\n",
    "    df_prep['CDLHARAMICROSS'] = talib.CDLHARAMICROSS(op, hi, lo, cl)\n",
    "\n",
    "       #-----------ALL PATTERNS---------#\n",
    "\n",
    "    df_prep['CDL2CROWS']           = talib.CDL2CROWS (op, hi, lo, cl)\n",
    "    df_prep['CDL3BLACKCROWS']      = talib.CDL3BLACKCROWS(op, hi, lo, cl)\n",
    "    df_prep['CDL3INSIDE']          = talib.CDL3INSIDE(op, hi, lo, cl)\n",
    "    df_prep['CDL3LINESTRIKE']      = talib.CDL3LINESTRIKE (op, hi, lo, cl)\n",
    "    df_prep['CDL3OUTSIDE']         = talib.CDL3OUTSIDE(op, hi, lo, cl)\n",
    "    df_prep['CDL3STARSINSOUTH']    = talib.CDL3STARSINSOUTH(op, hi, lo, cl)\n",
    "    df_prep['CDL3WHITESOLDIERS']   = talib.CDL3WHITESOLDIERS  (op, hi, lo, cl)\n",
    "    df_prep['CDLABANDONEDBABY']    = talib.CDLABANDONEDBABY(op, hi, lo, cl)\n",
    "    df_prep['CDLADVANCEBLOCK']     = talib.CDLADVANCEBLOCK (op, hi, lo, cl)\n",
    "    df_prep['CDLBELTHOLD']         = talib.CDLBELTHOLD(op, hi, lo, cl)\n",
    "    df_prep['CDLBREAKAWAY']        = talib.CDLBREAKAWAY  (op, hi, lo, cl)\n",
    "    df_prep['CDLCLOSINGMARUBOZU']  = talib.CDLCLOSINGMARUBOZU(op, hi, lo, cl)\n",
    "    df_prep['CDLCONCEALBABYSWALL'] = talib.CDLCONCEALBABYSWALL  (op, hi, lo, cl)\n",
    "    df_prep['CDLCOUNTERATTACK']    = talib.CDLCOUNTERATTACK(op, hi, lo, cl)\n",
    "    df_prep['CDLDARKCLOUDCOVER']   = talib.CDLDARKCLOUDCOVER (op, hi, lo, cl)\n",
    "    df_prep['CDLGAPSIDESIDEWHITE'] = talib.CDLGAPSIDESIDEWHITE  (op, hi, lo, cl)\n",
    "    df_prep['CDLHIGHWAVE']         = talib.CDLHIGHWAVE (op, hi, lo, cl)\n",
    "    df_prep['CDLHIKKAKE']          = talib.CDLHIKKAKE(op, hi, lo, cl)\n",
    "    df_prep['CDLHIKKAKEMOD']       = talib.CDLHIKKAKEMOD(op, hi, lo, cl)\n",
    "    df_prep['CDLHOMINGPIGEON']     = talib.CDLHOMINGPIGEON (op, hi, lo, cl)\n",
    "    df_prep['CDLIDENTICAL3CROWS']  = talib. CDLIDENTICAL3CROWS (op, hi, lo, cl)\n",
    "    df_prep['CDLINNECK']           = talib.CDLINNECK(op, hi, lo, cl)\n",
    "    df_prep['CDLINVERTEDHAMMER']   = talib.CDLINVERTEDHAMMER (op, hi, lo, cl)\n",
    "    df_prep['CDLKICKING']          = talib.CDLKICKING(op, hi, lo, cl)\n",
    "    df_prep['CDLKICKINGBYLENGTH']  = talib.CDLKICKINGBYLENGTH(op, hi, lo, cl)\n",
    "    df_prep['CDLLADDERBOTTOM']     = talib.CDLLADDERBOTTOM (op, hi, lo, cl)\n",
    "    df_prep['CDLLONGLEGGEDDOJI']   = talib.CDLLONGLEGGEDDOJI (op, hi, lo, cl)\n",
    "    df_prep['CDLLONGLINE']         = talib.CDLLONGLINE  (op, hi, lo, cl)\n",
    "    df_prep['CDLMARUBOZU']         = talib.CDLMARUBOZU(op, hi, lo, cl)\n",
    "    df_prep['CDLMATCHINGLOW']      = talib.CDLMATCHINGLOW(op, hi, lo, cl)\n",
    "    df_prep['CDLMATHOLD']          = talib.CDLMATHOLD  (op, hi, lo, cl)\n",
    "    df_prep['CDLONNECK']           = talib.CDLONNECK (op, hi, lo, cl)\n",
    "    df_prep['CDLPIERCING']         = talib.CDLPIERCING(op, hi, lo, cl)\n",
    "    df_prep['CDLRICKSHAWMAN']      = talib.CDLRICKSHAWMAN(op, hi, lo, cl)\n",
    "    df_prep['CDLRISEFALL3METHODS'] = talib.CDLRISEFALL3METHODS  (op, hi, lo, cl)\n",
    "    df_prep['CDLSEPARATINGLINES']  = talib.CDLSEPARATINGLINES(op, hi, lo, cl)\n",
    "    df_prep['CDLSHORTLINE']        = talib.CDLSHORTLINE  (op, hi, lo, cl)\n",
    "    df_prep['CDLSPINNINGTOP']      = talib.CDLSPINNINGTOP(op, hi, lo, cl)\n",
    "    df_prep['CDLSTALLEDPATTERN']   = talib.CDLSTALLEDPATTERN (op, hi, lo, cl)\n",
    "    df_prep['CDLSTICKSANDWICH']    = talib.CDLSTICKSANDWICH (op, hi, lo, cl)\n",
    "    df_prep['CDLTAKURI']           = talib.CDLTAKURI (op, hi, lo, cl)\n",
    "    df_prep['CDLTASUKIGAP']        = talib.CDLTASUKIGAP  (op, hi, lo, cl)\n",
    "    df_prep['CDLTHRUSTING']        = talib.CDLTHRUSTING  (op, hi, lo, cl)\n",
    "    df_prep['CDLTRISTAR']          = talib.CDLTRISTAR(op, hi, lo, cl)\n",
    "    df_prep['CDLUNIQUE3RIVER']     = talib.CDLUNIQUE3RIVER (op, hi, lo, cl)\n",
    "    df_prep['CDLUPSIDEGAP2CROWS']  = talib.CDLUPSIDEGAP2CROWS(op, hi, lo, cl)\n",
    "    df_prep['CDLXSIDEGAP3METHODS'] = talib.CDLXSIDEGAP3METHODS (op, hi, lo, cl)\n",
    "\n",
    "\n",
    "    #---------------------------Making Price Action------------------------------------------#\n",
    "    df_prep['Price_wrt_max_last_50'] = (df_prep['askclose'].rolling(window=50).max()/df_prep['askclose']) - 1\n",
    "    df_prep['Price_wrt_max_last_100'] = (df_prep['askclose'].rolling(window=100).max()/df_prep['askclose']) - 1\n",
    "    df_prep['Price_wrt_max_last_150'] = (df_prep['askclose'].rolling(window=150).max()/df_prep['askclose']) - 1\n",
    "    \n",
    "    df_prep['Price_wrt_min_last_50'] = 1-(df_prep['askclose'].rolling(window=50).min()/df_prep['askclose']) \n",
    "    df_prep['Price_wrt_min_last_100'] = 1-(df_prep['askclose'].rolling(window=100).min()/df_prep['askclose']) \n",
    "    df_prep['Price_wrt_min_last_150'] = 1-(df_prep['askclose'].rolling(window=150).min()/df_prep['askclose']) \n",
    "    \n",
    "    \n",
    "    col_names_candles = df_prep.columns\n",
    "    varlist_candles = [col for col in col_names_candles if col.startswith('CDL')]\n",
    "\n",
    "    for item in varlist_candles:\n",
    "        #---converting the candle value into 0 and 1---#\n",
    "        df_prep[item] = df_prep[item].astype(bool).astype(int)\n",
    "        it = item[0:len(item)]\n",
    "        #-----Making a rolling sum of 5------#\n",
    "        df_prep[it+\"_Rolling_5\"] = df_prep[item].rolling(window=5).sum()\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    ##---- MIN and MAX price---##\n",
    "    df_prep['Price_max_last_50'] = (df_prep['askclose'].rolling(window=50).max())\n",
    "    df_prep['Price_max_last_100'] = (df_prep['askclose'].rolling(window=100).max())\n",
    "    df_prep['Price_max_last_150'] = (df_prep['askclose'].rolling(window=150).max())\n",
    "    \n",
    "    df_prep['Price_min_last_50'] = (df_prep['askclose'].rolling(window=50).min())\n",
    "    df_prep['Price_min_last_100'] = (df_prep['askclose'].rolling(window=100).min())\n",
    "    df_prep['Price_min_last_150'] = (df_prep['askclose'].rolling(window=150).min())\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## ------ OverBought and OverSold Duration -----##\n",
    "\n",
    "    #Stochastic Oscillator\n",
    "    df_prep['Stoch_overbought'] = np.where(df_prep['_stock_%K']>80,1,0)\n",
    "    df_prep['Stoch_oversold'] = np.where(df_prep['_stock_%K']<20,1,0)\n",
    "    \n",
    "    df_prep['Stoch_overbought_%'] = ((df_prep['Stoch_overbought'].rolling(window=50).sum())/50)*100\n",
    "    df_prep['Stoch_oversold_%'] = ((df_prep['Stoch_oversold'].rolling(window=50).sum())/50)*100\n",
    "\n",
    "    \n",
    "    #Relative Strength Index\n",
    "    df_prep['RSI_overbought'] = np.where(df_prep['momentum_rsi']>70,1,0)\n",
    "    df_prep['RSI_oversold'] = np.where(df_prep['momentum_rsi']<30,1,0)\n",
    "    \n",
    "    df_prep['RSI_overbought_%'] = ((df_prep['RSI_overbought'].rolling(window=50).sum())/50)*100\n",
    "    df_prep['RSI_oversold_%'] = ((df_prep['RSI_oversold'].rolling(window=50).sum())/50)*100\n",
    "    \n",
    "    #True strength index\n",
    "    df_prep['TSI_overbought'] = np.where(df_prep['momentum_tsi']>0,1,0)\n",
    "    df_prep['TSI_oversold'] = np.where(df_prep['momentum_tsi']<0,1,0)\n",
    "    \n",
    "    df_prep['TSI_overbought_%'] = ((df_prep['TSI_overbought'].rolling(window=50).sum())/50)*100\n",
    "    df_prep['TSI_oversold_%'] = ((df_prep['TSI_oversold'].rolling(window=50).sum())/50)*100\n",
    "    \n",
    "    \n",
    "    #Ultimate Oscillator\n",
    "    df_prep['UO_overbought'] = np.where(df_prep['momentum_uo']>70,1,0)\n",
    "    df_prep['UO_oversold'] = np.where(df_prep['momentum_uo']<30,1,0)\n",
    "    \n",
    "    df_prep['UO_overbought_%'] = ((df_prep['UO_overbought'].rolling(window=50).sum())/50)*100\n",
    "    df_prep['UO_oversold_%'] = ((df_prep['UO_oversold'].rolling(window=50).sum())/50)*100\n",
    "    \n",
    "    \n",
    "    #Williams %R\n",
    "    df_prep['Williams %R_overbought'] = np.where(((df_prep['momentum_wr']<0) & (df_prep['momentum_wr']>-20)),1,0)\n",
    "    df_prep['Williams %R_oversold'] = np.where(((df_prep['momentum_wr']>-80) & (df_prep['momentum_wr']<-100)),1,0)\n",
    "    \n",
    "    df_prep['Williams %R_overbought_%'] = ((df_prep['Williams %R_overbought'].rolling(window=50).sum())/50)*100\n",
    "    df_prep['Williams %R_oversold_%'] = ((df_prep['Williams %R_oversold'].rolling(window=50).sum())/50)*100\n",
    "    \n",
    "    \n",
    "    #Money Flow Index\n",
    "    df_prep['MFI_overbought'] = np.where(df_prep['momentum_mfi']>80,1,0)\n",
    "    df_prep['MFI_oversold'] = np.where(df_prep['momentum_mfi']<20,1,0)\n",
    "    \n",
    "    df_prep['MFI_overbought_%'] = ((df_prep['MFI_overbought'].rolling(window=50).sum())/50)*100\n",
    "    df_prep['MFI_oversold_%'] = ((df_prep['MFI_oversold'].rolling(window=50).sum())/50)*100\n",
    "    \n",
    "    #----------------------#\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## ------ OverBought and OverSold Recency ---- ##\n",
    "    list_1 = ['Stoch','RSI','TSI','UO','Williams %R','MFI']\n",
    "    \n",
    "    for i in list_1:\n",
    "        df_prep[i+'_overbought_sum'] = 0\n",
    "        df_prep[i+'_oversold_sum'] = 0\n",
    "    \n",
    "    \n",
    "    for j in range(0,df_prep.shape[0]):\n",
    "        for i in list_1:\n",
    "#             df_prep[i+'_overbought_sum'] = 0\n",
    "#             df_prep[i+'_oversold_sum'] = 0\n",
    "        \n",
    "            if j==0:\n",
    "                df_prep[i+'_overbought_sum'][j] = df_prep[i+'_overbought'][j]\n",
    "                \n",
    "            elif(df_prep[i+'_overbought'][j]==1):\n",
    "                df_prep[i+'_overbought_sum'][j] = df_prep[i+'_overbought'][j]+df_prep[i+'_overbought_sum'][j-1]\n",
    "            else:\n",
    "                df_prep[i+'_overbought_sum'][j] = 0\n",
    "            \n",
    "            \n",
    "            if j==0:\n",
    "                df_prep[i+'_oversold_sum'][j] = df_prep[i+'_oversold'][j]\n",
    "                \n",
    "            elif(df_prep[i+'_oversold'][j]==1):\n",
    "                df_prep[i+'_oversold_sum'][j] = df_prep[i+'_oversold'][j]+df_prep[i+'_oversold_sum'][j-1]\n",
    "            else:\n",
    "                df_prep[i+'_oversold_sum'][j] = 0\n",
    "\n",
    "\n",
    "\n",
    "    # ------ TTM Squeeze indicator ------#\n",
    "    \n",
    "    df_prep['30 Day MA'] = df_prep['askclose'].rolling(window = 20).mean()\n",
    "    df_prep['30 Day STD'] = df_prep['askclose'].rolling(window = 20).std()\n",
    "    df_prep['Upper Band'] = df_prep['30 Day MA'] + (df_prep['30 Day STD'] * 2)\n",
    "    df_prep['Lower Band'] = df_prep['30 Day MA'] - (df_prep['30 Day STD'] * 2)\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "    \n",
    "\n",
    "    print(\" Data prep done \") \n",
    "    \n",
    "    df_prep.ffill()\n",
    "            \n",
    "    final_data= pd.concat([final_data,df_prep],axis =0 , ignore_index =True)   \n",
    "            \n",
    "    clear_output()    \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### creation of iteration table for data preparation\n",
    "row_count.reset_index(inplace=True)\n",
    "iteration_table = row_count[['Currency','TimeFrame']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##iteration_table = iteration_table.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#iteration_table\n",
    "global final_data\n",
    "global counter \n",
    "counter = 0\n",
    "final_data =pd.DataFrame()\n",
    "data_prep = iteration_table.apply(lambda row :model_data_prep(row['Currency'],row['TimeFrame']),axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(\"C:/Users/Administrator/WSG Markets/10 Year data creation for model/Creating model data for all strategy combined/Strategy - 1_1 TP Ratio/Indicator Dataset/Indicator Data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
